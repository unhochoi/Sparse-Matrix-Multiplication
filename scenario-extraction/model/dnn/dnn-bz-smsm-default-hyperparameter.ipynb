{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450fe173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b929f3b5",
   "metadata": {},
   "source": [
    "### 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab44c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/dataset/spmm-latency-dataset/extract-dataset-using-d-optimal/dataset-for-compare-random/nonsquare-train-1035-from-spmm-contain-todense-over-3s-1293.csv')\n",
    "test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/dataset/spmm-latency-dataset/extract-dataset-using-d-optimal/dataset-for-compare-random/nonsquare-test-258-from-spmm-contain-todense-over-3s-1293.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd230dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train = train[['lr','lc','rc','ld','rd','lnnz','rnnz']] \n",
    "y_train = train['bz_smsm']\n",
    "\n",
    "# Test\n",
    "X_test = test[['lr','lc','rc','ld','rd','lnnz','rnnz']] \n",
    "y_test = test['bz_smsm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27130815",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9dafbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# 훈련데이터의 모수 분포 저장\n",
    "minmax_scaler.fit(X_train)\n",
    "\n",
    "# 훈련 데이터 스케일링\n",
    "X_train = minmax_scaler.transform(X_train)\n",
    "\n",
    "# 테스트 데이터 스케일링\n",
    "X_test = minmax_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036c165",
   "metadata": {},
   "source": [
    "### Metric 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f747aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    rmse = K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32358a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471ce60",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning 대상 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bd26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning 대상 모델 정의\n",
    "def create_model(dense_nparams, dense_layer_sizes , input_optimizer, input_kernel_initializer, input_dropout, input_lr):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(dense_nparams, activation=\"relu\", input_shape=(X_train.shape[1],), kernel_initializer=input_kernel_initializer))  \n",
    "    model.add(Dropout(input_dropout),)\n",
    "    \n",
    "    # dense_layer_sizes 만큼 layer 추가\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size, activation='relu', kernel_initializer=input_kernel_initializer))\n",
    "        model.add(Dropout(input_dropout), )\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = input_optimizer(lr=input_lr)\n",
    "    \n",
    "    model.compile(optimizer = optimizer ,\n",
    "                  loss='mape',\n",
    "                  metrics=['mape',rmse])\n",
    "    return model\n",
    "\n",
    "# hyperparameter tuning 대상 모델 선언\n",
    "# 파라미터 조합 당 epochs 는 400 번\n",
    "regressor_model = KerasRegressor(build_fn=create_model, epochs=400, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defc878",
   "metadata": {},
   "source": [
    "### GridSearchCV 정의 및 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e5ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross_validation 정의\n",
    "# kf = KFold(random_state=30,\n",
    "#            n_splits=10, # Fold 는 10개로 지정\n",
    "#            shuffle=True\n",
    "#           )\n",
    "\n",
    "# # gridsearch 정의\n",
    "# # scoring : 검증셋의 성능을 무엇으로 측정할 것인지\n",
    "# # n_jobs : 프로세스가 시스템의 모든 코어를 사용하도록    \n",
    "# # verbose : 모든 log 출력하도록\n",
    "# grid = GridSearchCV(estimator=regressor_model, \n",
    "#                     param_grid=param_grid, \n",
    "#                     scoring = make_scorer(mean_absolute_percentage_error, greater_is_better=False),\n",
    "#                     cv = kf,\n",
    "#                     n_jobs=-1,\n",
    "#                     verbose=3)\n",
    "\n",
    "# # gridsearch 시작\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # gridesearch 결과\n",
    "# print(\"최고의 파라미터 :\", grid_result.best_params_)\n",
    "# print(\"최고 평균 정확도 : {}\".format(grid_result.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36c5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b503abaf",
   "metadata": {},
   "source": [
    "### GridSearchCV 를 통해 탐색된 최적의 Hyperparameter 를 사용해 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "142a6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# result_model = create_model(grid_result.best_params_['dense_nparams'],\n",
    "#                             grid_result.best_params_['dense_layer_sizes'],\n",
    "#                             grid_result.best_params_['input_optimizer'],\n",
    "#                             grid_result.best_params_['input_kernel_initializer'],\n",
    "#                             grid_result.best_params_['input_dropout'],\n",
    "#                             grid_result.best_params_['input_lr'])\n",
    "# # 모델 훈련\n",
    "# history = result_model.fit(X_train, \n",
    "#                 y_train,\n",
    "#                 epochs=400, \n",
    "#                 validation_split = 0.1, \n",
    "#                 verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e755818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = pd.DataFrame(history.history)\n",
    "# hist['epoch'] = history.epoch\n",
    "# hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba714adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history):\n",
    "#     hist = pd.DataFrame(history.history)\n",
    "#     hist['epoch'] = history.epoch\n",
    "\n",
    "#     plt.figure(figsize=(8,12))\n",
    "\n",
    "#     # mape metric\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('mape')\n",
    "#     plt.plot(hist['epoch'], hist['mape'],\n",
    "#            label='Train Error')\n",
    "#     plt.plot(hist['epoch'], hist['val_mape'],\n",
    "#            label = 'Val Error')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     # rmse metric\n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('rmse')\n",
    "#     plt.plot(hist['epoch'], hist['rmse'],\n",
    "#            label='Train Error')\n",
    "#     plt.plot(hist['epoch'], hist['val_rmse'],\n",
    "#            label = 'Val Error')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbff91",
   "metadata": {},
   "source": [
    "### 예측 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34575ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 훈련데이터 예측\n",
    "# y_train_pred = result_model.predict(X_train).reshape(-1,)\n",
    "# print(\"훈련데이터 예측 mape : {}\\n\".format(mean_absolute_percentage_error(y_train,y_train_pred)))\n",
    "\n",
    "# # 테스트데이터 예측\n",
    "# y_test_pred = result_model.predict(X_test).reshape(-1,)\n",
    "# print(\"테스트데이터 예측 mape : {}\\n\".format(mean_absolute_percentage_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ece82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a9d9",
   "metadata": {},
   "source": [
    "### 고정된 Hyperparameter 를 사용해 모델링 (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57248131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# fix_model = create_model(100,\n",
    "#                             (100, 100, 100, 100),\n",
    "#                             Adam,\n",
    "#                             'uniform',\n",
    "#                             0,\n",
    "#                             0.001)\n",
    "\n",
    "# # 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "# class PrintDot(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         if epoch % 100 == 0: print('')\n",
    "#         #print(\"epoch : {}, logs : {}\".format(epoch,logs))\n",
    "#         print('.', end='')\n",
    "\n",
    "# # monitor는 어떤 매개변수를 볼 것인지 입니다.\n",
    "# # patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다\n",
    "# # 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_mape', patience=100)\n",
    "\n",
    "# EPOCHS = 200\n",
    "\n",
    "# # 훈련 정확도와 검증 정확도 출력\n",
    "# # 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 콜백(callback)을 사용합니다.\n",
    "# # history = fix_model.fit(X_train, \n",
    "# #                     y_train,\n",
    "# #                     epochs=EPOCHS, \n",
    "# #                     validation_split = 0.1, \n",
    "# #                     verbose =0, \n",
    "# #                     callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "# history = fix_model.fit(X_train, \n",
    "#                     y_train,\n",
    "#                     epochs=EPOCHS, \n",
    "#                     validation_split = 0.1, \n",
    "#                     verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b0b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = pd.DataFrame(history.history)\n",
    "# hist['epoch'] = history.epoch\n",
    "# hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc0fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history):\n",
    "#     hist = pd.DataFrame(history.history)\n",
    "#     hist['epoch'] = history.epoch\n",
    "\n",
    "#     plt.figure(figsize=(8,12))\n",
    "\n",
    "#     # mape metric\n",
    "#     plt.subplot(2,1,1)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('mape')\n",
    "#     plt.plot(hist['epoch'], hist['mape'],\n",
    "#            label='Train Error')\n",
    "#     plt.plot(hist['epoch'], hist['val_mape'],\n",
    "#            label = 'Val Error')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     # rmse metric\n",
    "#     plt.subplot(2,1,2)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('rmse')\n",
    "#     plt.plot(hist['epoch'], hist['rmse'],\n",
    "#            label='Train Error')\n",
    "#     plt.plot(hist['epoch'], hist['val_rmse'],\n",
    "#            label = 'Val Error')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cf10902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 훈련데이터 예측\n",
    "# y_train_pred = fix_model.predict(X_train).reshape(-1,)\n",
    "# print(\"훈련데이터 예측 mape : {}\\n\".format(mean_absolute_percentage_error(y_train,y_train_pred)))\n",
    "\n",
    "# # 테스트데이터 예측\n",
    "# y_test_pred = fix_model.predict(X_test).reshape(-1,)\n",
    "# print(\"테스트데이터 예측 mape : {}\\n\".format(mean_absolute_percentage_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4695db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e96ef7aa",
   "metadata": {},
   "source": [
    "### Default Hyperparameter 를 고정한뒤, 훈련 데이터를 섞어가며 MAPE 결과 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb8b729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "............................................................................\n",
      ".................................................................................\n",
      ".................................................................................\n",
      "...................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "............................................\n",
      "....................................................................................................\n",
      ".......................................\n",
      "...........................................................................................\n",
      ".................................................................................\n",
      "........................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".............\n",
      "...................................................................................\n",
      "..................................................................................\n",
      ".......................................................................................\n",
      "................................................................................................\n",
      "...................................................................................\n",
      "....................................................................................................\n",
      ".........\n",
      "....................................................................................................\n",
      "...........................................\n",
      "..........................................................................................\n",
      "...........................................................................................\n",
      "....................................................................................................\n",
      "............\n",
      " [73.59457206 73.53308453 73.48506925 73.42457338 73.06637528 72.96475178\n",
      " 72.92516241 72.89277115 72.85756597 72.81762394 72.82480209 72.83640735\n",
      " 72.86434398 72.88945374 72.89950708 72.90805015 72.91990427 72.92577101\n",
      " 72.94176229 72.95382611]\n",
      "median :  72.92253333947497\n",
      "min :  72.81762394203149\n",
      "max :  73.59457206479219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mape_list = []\n",
    "\n",
    "# hyperparameter tuning 대상 모델 정의\n",
    "def create_model():\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(100, activation=\"relu\", input_shape=(X_train.shape[1],), kernel_initializer='uniform'))  \n",
    "    model.add(Dropout(0),)    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    \n",
    "    model.compile(optimizer = optimizer ,\n",
    "                  loss='mape',\n",
    "                  metrics=['mape',rmse])\n",
    "    return model\n",
    "\n",
    "# 모델 정의\n",
    "fix_model = create_model()\n",
    "\n",
    "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        #print(\"epoch : {}, logs : {}\".format(epoch,logs))\n",
    "        print('.', end='')\n",
    "\n",
    "# monitor는 어떤 매개변수를 볼 것인지 입니다.\n",
    "# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다\n",
    "# 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_mape', patience=80)\n",
    "\n",
    "EPOCHS = 1000\n",
    "    \n",
    "for i in range(20):\n",
    "\n",
    "    # 훈련 정확도와 검증 정확도 출력\n",
    "    # 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 콜백(callback)을 사용합니다.\n",
    "    history = fix_model.fit(X_train, \n",
    "                        y_train,\n",
    "                        epochs=EPOCHS, \n",
    "                        validation_split = 0.1, \n",
    "                        verbose =0, \n",
    "                        callbacks=[early_stop, PrintDot()])\n",
    "    \n",
    "    # 테스트데이터 예측\n",
    "    y_test_pred = fix_model.predict(X_test).reshape(-1,)\n",
    "    \n",
    "    mape_list.append(mean_absolute_percentage_error(y_test,y_test_pred))\n",
    "\n",
    "mape_list = np.array(mape_list)\n",
    "print(\"\\n\",mape_list)\n",
    "print(\"median : \" , np.median(mape_list))\n",
    "print(\"min : \" , np.min(mape_list))\n",
    "print(\"max : \" , np.max(mape_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5bebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
