{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1035, 258\n",
    "train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/spmm-latency-traintest/train-test-csv/nonsquare-train-1035-from-spmm-contain-todense-over-3s-1293.csv')\n",
    "test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/spmm-latency-traintest/train-test-csv/nonsquare-test-258-from-spmm-contain-todense-over-3s-1293.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + Valid (ld*rd, LR*RC*LD*RD, LR*LC*RC*LD*RD, LNNZ*RNNZ 제거)\n",
    "#MAPE 13\n",
    "X_train = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n",
    "y_train = train['sp_smdm']\n",
    "\n",
    "# Test\n",
    "X_test = test[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n",
    "y_test = test['sp_smdm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train + Valid ('lr*lc*rc', LR*RC*LD*RD, LR*LC*RC*LD*RD, LNNZ*RNNZ 제거)\n",
    "# # MAPE 12\n",
    "# X_train = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc','ld*rd']] \n",
    "# y_train = train['sp_smdm']\n",
    "\n",
    "# # Test\n",
    "# X_test = test[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc','ld*rd']] \n",
    "# y_test = test['sp_smdm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화(Standardization)\n",
    "# 회귀 문제에선 MinMaxScaler가 좋음\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 변형 객체 생성\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# 훈련데이터의 모수 분포 저장\n",
    "minmax_scaler.fit(X_train)\n",
    "\n",
    "# 훈련 데이터 스케일링\n",
    "X_train = minmax_scaler.transform(X_train)\n",
    "\n",
    "# 테스트 데이터의 스케일링\n",
    "X_test = minmax_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    rmse = K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def build_model():\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Dense(512, activation=\"relu\", input_shape=(X_train.shape[1],)))  \n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adagrad(lr=0.1)\n",
    "    \n",
    "    model.compile(optimizer=optimizer ,\n",
    "                  loss='mape',\n",
    "                  metrics=['mape',rmse])\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        #print(\"epoch : {}, logs : {}\".format(epoch,logs))\n",
    "        print('.', end='')\n",
    "\n",
    "# monitor는 어떤 매개변수를 볼 것인지 입니다.\n",
    "# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다\n",
    "# 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_mape', patience=50)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "# 훈련 정확도와 검증 정확도 출력\n",
    "# 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 콜백(callback)을 사용합니다.\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_split = 0.1, \n",
    "                    verbose =0, \n",
    "                    callbacks=[early_stop, PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure(figsize=(8,12))\n",
    "\n",
    "    # mape metric\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('mape')\n",
    "    plt.plot(hist['epoch'], hist['mape'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mape'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    \n",
    "    # rmse metric\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('rmse')\n",
    "    plt.plot(hist['epoch'], hist['rmse'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_rmse'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mape_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "def rmse_error(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean(np.square(y_pred - y_true))) \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터 예측\n",
    "y_train_pred = model.predict(X_train).reshape(-1,)\n",
    "print(\"-------- 훈련데이터 예측 --------------------------\")\n",
    "print(\"rmse : {}\".format(rmse_error(y_train,y_train_pred)))\n",
    "print(\"mape : {}\".format(mape_error(y_train,y_train_pred)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 테스트데이터 예측\n",
    "y_pred = model.predict(X_test).reshape(-1,)\n",
    "print(\"-------- 테스트데이터 예측 -------------------------\")\n",
    "print(\"rmse : {}\".format(rmse_error(y_test,y_pred)))\n",
    "print(\"mape : {}\".format(mape_error(y_test,y_pred)))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
