{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/spmm-latency-traintest/train-test-csv/nonsquare-train-1035-from-spmm-contain-todense-over-3s-1293.csv')\n",
    "test = pd.read_csv('/Users/bdlab/Desktop/sparse-matrix-multiplication/scenario-extraction/d-optimal/spmm-latency-traintest/train-test-csv/nonsquare-test-258-from-spmm-contain-todense-over-3s-1293.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train = train[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n",
    "sp_smdm_y_train = train['sp_smdm']\n",
    "bz_smsm_y_train = train['bz_smsm']\n",
    "\n",
    "# Test\n",
    "X_test = test[['lr','lc','rc','ld','rd','lnnz','rnnz','lr*lc','lc*rc','lr*rc']] \n",
    "sp_smdm_y_test = test['sp_smdm']\n",
    "bz_smsm_y_test = test['bz_smsm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# 훈련데이터의 모수 분포 저장\n",
    "minmax_scaler.fit(X_train)\n",
    "\n",
    "# 훈련 데이터 스케일링\n",
    "X_train = minmax_scaler.transform(X_train)\n",
    "\n",
    "# 테스트 데이터 스케일링\n",
    "X_test = minmax_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    rmse = K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dense_nparams, dense_layer_sizes , input_optimizer, input_kernel_initializer, input_dropout, input_lr):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(dense_nparams, activation=\"relu\", input_shape=(X_train.shape[1],), kernel_initializer=input_kernel_initializer))  \n",
    "    model.add(Dropout(input_dropout),)\n",
    "    \n",
    "    # dense_layer_sizes 만큼 layer 추가\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size, activation='relu', kernel_initializer=input_kernel_initializer))\n",
    "        model.add(Dropout(input_dropout), )\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = input_optimizer(lr=input_lr)\n",
    "    \n",
    "    model.compile(optimizer = optimizer ,\n",
    "                  loss='mape',\n",
    "                  metrics=['mape',rmse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sp_smdm dnn 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "........"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "sp_smdm_model = create_model(1024,\n",
    "                            (128, 64, 32, 16),\n",
    "                            Adagrad,\n",
    "                            'normal',\n",
    "                            0,\n",
    "                            0.07)\n",
    "\n",
    "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        #print(\"epoch : {}, logs : {}\".format(epoch,logs))\n",
    "        print('.', end='')\n",
    "\n",
    "# monitor는 어떤 매개변수를 볼 것인지 입니다.\n",
    "# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다\n",
    "# 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_mape', patience=100)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "# 훈련 정확도와 검증 정확도 출력\n",
    "# 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 콜백(callback)을 사용합니다.\n",
    "history = sp_smdm_model.fit(X_train, \n",
    "                    sp_smdm_y_train,\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_split = 0.1, \n",
    "                    verbose =0, \n",
    "                    callbacks=[early_stop, PrintDot()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bz_smsm dnn 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".................................................."
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "bz_smsm_model = create_model(1024,\n",
    "                            (128, 64, 32, 16),\n",
    "                            Adagrad,\n",
    "                            'normal',\n",
    "                            0,\n",
    "                            0.07)\n",
    "\n",
    "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        #print(\"epoch : {}, logs : {}\".format(epoch,logs))\n",
    "        print('.', end='')\n",
    "\n",
    "# monitor는 어떤 매개변수를 볼 것인지 입니다.\n",
    "# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다\n",
    "# 지정된 에포크 횟수 동안 성능 향상이 없으면 자동으로 훈련이 멈춥니다.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_mape', patience=100)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "# 훈련 정확도와 검증 정확도 출력\n",
    "# 에포크마다 훈련 상태를 점검하기 위해 EarlyStopping 콜백(callback)을 사용합니다.\n",
    "history = bz_smsm_model.fit(X_train, \n",
    "                    bz_smsm_y_train,\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_split = 0.1, \n",
    "                    verbose =0, \n",
    "                    callbacks=[early_stop, PrintDot()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_smdm 테스트데이터 예측 mape : 11.910960110207942\n",
      "\n",
      "bz_smsm 테스트데이터 예측 mape : 12.752562166093403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sp_smdm 테스트데이터 예측\n",
    "sp_smdm_y_pred = sp_smdm_model.predict(X_test).reshape(-1,)\n",
    "print(\"sp_smdm 테스트데이터 예측 mape : {}\\n\".format(mean_absolute_percentage_error(sp_smdm_y_test,sp_smdm_y_pred)))\n",
    "\n",
    "# bz_smsm 테스트데이터 예측\n",
    "bz_smsm_y_pred = bz_smsm_model.predict(X_test).reshape(-1,)\n",
    "print(\"bz_smsm 테스트데이터 예측 mape : {}\\n\".format(mean_absolute_percentage_error(bz_smsm_y_test,bz_smsm_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측한, sp_smdm_y_pred 와 bz_smsm_y_pred 중 작은 값으로 y_pred_label 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    latency_list = []\n",
    "    latency_list.append(sp_smdm_y_pred[i])\n",
    "    latency_list.append(bz_smsm_y_pred[i])\n",
    "    y_pred_label.append(latency_list.index(min(latency_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제값인, sp_smdm_y_test 과 bz_smsm_y_test 을 통해, y_real_label 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real_label = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    latency_list = []\n",
    "    latency_list.append(test.loc[i,'sp_smdm'])\n",
    "    latency_list.append(test.loc[i,'bz_smsm'])\n",
    "    y_real_label.append(latency_list.index(min(latency_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_pred_label 과 y_real_label 간 accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573643410852714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_label, y_real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>lc</th>\n",
       "      <th>rc</th>\n",
       "      <th>ld</th>\n",
       "      <th>rd</th>\n",
       "      <th>lnnz</th>\n",
       "      <th>rnnz</th>\n",
       "      <th>sp_smdm</th>\n",
       "      <th>bz_smsm</th>\n",
       "      <th>y_pred_label</th>\n",
       "      <th>sp_smdm_y_pred</th>\n",
       "      <th>bz_smsm_y_pred</th>\n",
       "      <th>y_real_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131403</td>\n",
       "      <td>43733</td>\n",
       "      <td>7722</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.10</td>\n",
       "      <td>484397</td>\n",
       "      <td>33774444</td>\n",
       "      <td>29621</td>\n",
       "      <td>34386</td>\n",
       "      <td>0</td>\n",
       "      <td>29454</td>\n",
       "      <td>36816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15728</td>\n",
       "      <td>31500</td>\n",
       "      <td>45522</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4263462</td>\n",
       "      <td>43019639</td>\n",
       "      <td>247887</td>\n",
       "      <td>116536</td>\n",
       "      <td>1</td>\n",
       "      <td>201186</td>\n",
       "      <td>129839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32231</td>\n",
       "      <td>80720</td>\n",
       "      <td>577</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4176859</td>\n",
       "      <td>13985604</td>\n",
       "      <td>3975</td>\n",
       "      <td>6960</td>\n",
       "      <td>0</td>\n",
       "      <td>4333</td>\n",
       "      <td>7006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33895</td>\n",
       "      <td>53317</td>\n",
       "      <td>26714</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6696942</td>\n",
       "      <td>14243336</td>\n",
       "      <td>280837</td>\n",
       "      <td>92404</td>\n",
       "      <td>1</td>\n",
       "      <td>264359</td>\n",
       "      <td>92275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124226</td>\n",
       "      <td>83003</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.23</td>\n",
       "      <td>38209922</td>\n",
       "      <td>44118447</td>\n",
       "      <td>312134</td>\n",
       "      <td>224158</td>\n",
       "      <td>1</td>\n",
       "      <td>280096</td>\n",
       "      <td>222585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>26143</td>\n",
       "      <td>60856</td>\n",
       "      <td>21307</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2608393</td>\n",
       "      <td>12967105</td>\n",
       "      <td>88332</td>\n",
       "      <td>37055</td>\n",
       "      <td>1</td>\n",
       "      <td>86052</td>\n",
       "      <td>33104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2629</td>\n",
       "      <td>50352</td>\n",
       "      <td>42240</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.03</td>\n",
       "      <td>241666</td>\n",
       "      <td>63807645</td>\n",
       "      <td>40930</td>\n",
       "      <td>12841</td>\n",
       "      <td>1</td>\n",
       "      <td>32018</td>\n",
       "      <td>14190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>149605</td>\n",
       "      <td>87549</td>\n",
       "      <td>749</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4183568</td>\n",
       "      <td>9836644</td>\n",
       "      <td>10982</td>\n",
       "      <td>17169</td>\n",
       "      <td>0</td>\n",
       "      <td>9259</td>\n",
       "      <td>15255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>44373</td>\n",
       "      <td>7434</td>\n",
       "      <td>41589</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.13</td>\n",
       "      <td>185611</td>\n",
       "      <td>40196551</td>\n",
       "      <td>40966</td>\n",
       "      <td>86949</td>\n",
       "      <td>0</td>\n",
       "      <td>36936</td>\n",
       "      <td>74643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>59421</td>\n",
       "      <td>10745</td>\n",
       "      <td>7366</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.30</td>\n",
       "      <td>690710</td>\n",
       "      <td>23745843</td>\n",
       "      <td>18578</td>\n",
       "      <td>55799</td>\n",
       "      <td>0</td>\n",
       "      <td>15176</td>\n",
       "      <td>51608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr     lc     rc        ld    rd      lnnz      rnnz  sp_smdm  \\\n",
       "0    131403  43733   7722  0.000084  0.10    484397  33774444    29621   \n",
       "1     15728  31500  45522  0.008605  0.03   4263462  43019639   247887   \n",
       "2     32231  80720    577  0.001605  0.30   4176859  13985604     3975   \n",
       "3     33895  53317  26714  0.003706  0.01   6696942  14243336   280837   \n",
       "4    124226  83003   2310  0.003706  0.23  38209922  44118447   312134   \n",
       "..      ...    ...    ...       ...   ...       ...       ...      ...   \n",
       "187   26143  60856  21307  0.001639  0.01   2608393  12967105    88332   \n",
       "188    2629  50352  42240  0.001825  0.03    241666  63807645    40930   \n",
       "189  149605  87549    749  0.000319  0.15   4183568   9836644    10982   \n",
       "190   44373   7434  41589  0.000563  0.13    185611  40196551    40966   \n",
       "191   59421  10745   7366  0.001082  0.30    690710  23745843    18578   \n",
       "\n",
       "     bz_smsm  y_pred_label  sp_smdm_y_pred  bz_smsm_y_pred  y_real_label  \n",
       "0      34386             0           29454           36816             0  \n",
       "1     116536             1          201186          129839             1  \n",
       "2       6960             0            4333            7006             0  \n",
       "3      92404             1          264359           92275             1  \n",
       "4     224158             1          280096          222585             1  \n",
       "..       ...           ...             ...             ...           ...  \n",
       "187    37055             1           86052           33104             1  \n",
       "188    12841             1           32018           14190             1  \n",
       "189    17169             0            9259           15255             0  \n",
       "190    86949             0           36936           74643             0  \n",
       "191    55799             0           15176           51608             0  \n",
       "\n",
       "[192 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = test[['lr','lc','rc','ld','rd','lnnz','rnnz','sp_smdm','bz_smsm']]\n",
    "pd.concat([temp,pd.DataFrame(y_pred_label,columns=['y_pred_label']),pd.DataFrame(sp_smdm_y_pred,columns=['sp_smdm_y_pred']),pd.DataFrame(bz_smsm_y_pred,columns=['bz_smsm_y_pred']), pd.DataFrame(y_real_label,columns=['y_real_label']) ],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
